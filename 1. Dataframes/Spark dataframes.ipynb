{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. start a spark session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_dataframes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- var1: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- var2: string (nullable = true)\n",
      " |-- electricity_consumption: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. load a csv file and infer the datatypes......and what does the schema look like?\n",
    "df = spark.read.csv(\"D:\\\\Udemy course\\\\Spark\\\\Datasets\\\\train.csv\", inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'datetime',\n",
       " 'temperature',\n",
       " 'var1',\n",
       " 'pressure',\n",
       " 'windspeed',\n",
       " 'var2',\n",
       " 'electricity_consumption']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. What are the column names?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=0, datetime=datetime.datetime(2013, 7, 1, 0, 0), temperature=-11.4, var1=-17.1, pressure=1003.0, windspeed=571.91, var2='A', electricity_consumption=216.0),\n",
       " Row(ID=1, datetime=datetime.datetime(2013, 7, 1, 1, 0), temperature=-12.1, var1=-19.3, pressure=996.0, windspeed=575.04, var2='A', electricity_consumption=210.0),\n",
       " Row(ID=2, datetime=datetime.datetime(2013, 7, 1, 2, 0), temperature=-12.9, var1=-20.0, pressure=1000.0, windspeed=578.435, var2='A', electricity_consumption=225.0),\n",
       " Row(ID=3, datetime=datetime.datetime(2013, 7, 1, 3, 0), temperature=-11.4, var1=-17.1, pressure=995.0, windspeed=582.58, var2='A', electricity_consumption=216.0),\n",
       " Row(ID=4, datetime=datetime.datetime(2013, 7, 1, 4, 0), temperature=-11.4, var1=-19.3, pressure=1005.0, windspeed=586.6, var2='A', electricity_consumption=222.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. print out first 5 rows......\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------+-----+--------+\n",
      "| ID|            datetime|temperature| var1|pressure|\n",
      "+---+--------------------+-----------+-----+--------+\n",
      "|  0|2013-07-01 00:00:...|      -11.4|-17.1|  1003.0|\n",
      "|  1|2013-07-01 01:00:...|      -12.1|-19.3|   996.0|\n",
      "|  2|2013-07-01 02:00:...|      -12.9|-20.0|  1000.0|\n",
      "|  3|2013-07-01 03:00:...|      -11.4|-17.1|   995.0|\n",
      "|  4|2013-07-01 04:00:...|      -11.4|-19.3|  1005.0|\n",
      "|  5|2013-07-01 05:00:...|      -10.7|-19.3|  1013.0|\n",
      "|  6|2013-07-01 06:00:...|      -13.6|-17.1|  1006.0|\n",
      "|  7|2013-07-01 07:00:...|      -11.4|-17.9|   997.0|\n",
      "|  8|2013-07-01 08:00:...|      -10.7|-18.6|  1012.0|\n",
      "|  9|2013-07-01 09:00:...|      -10.0|-16.4|  1002.0|\n",
      "| 10|2013-07-01 10:00:...|       -7.1|-17.1|  1008.0|\n",
      "| 11|2013-07-01 11:00:...|       -7.9|-17.9|  1003.0|\n",
      "| 12|2013-07-01 12:00:...|       -5.7|-15.0|   998.0|\n",
      "| 13|2013-07-01 13:00:...|       -6.4|-14.3|  1008.0|\n",
      "| 14|2013-07-01 14:00:...|       -3.6|-15.0|   999.0|\n",
      "| 15|2013-07-01 15:00:...|       -5.0|-14.3|   997.0|\n",
      "| 16|2013-07-01 16:00:...|       -4.3|-16.4|  1009.0|\n",
      "| 17|2013-07-01 17:00:...|       -7.1|-18.6|  1003.0|\n",
      "| 18|2013-07-01 18:00:...|       -7.1|-16.4|  1007.0|\n",
      "| 19|2013-07-01 19:00:...|       -6.4|-16.4|   996.0|\n",
      "+---+--------------------+-----------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. print out first 5 columns......\n",
    "df.select(['ID','datetime','temperature','var1','pressure']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-------------------+-----------------+------------------+-----+-----------------------+\n",
      "|summary|                ID|      temperature|               var1|         pressure|         windspeed| var2|electricity_consumption|\n",
      "+-------+------------------+-----------------+-------------------+-----------------+------------------+-----+-----------------------+\n",
      "|  count|             26496|            26496|              26496|            26496|             26496|26496|                  26496|\n",
      "|   mean|           17455.5|5.098988526570052|-1.9162326388888922|986.4506151871981|23.959956408517844| null|      298.3596014492754|\n",
      "| stddev|10122.873672526148|  8.6828603086732|  10.42486026674354|12.00264663833323| 48.28032080686312| null|     108.02055533236155|\n",
      "|    min|                 0|            -17.1|              -32.9|            953.0|             1.075|    A|                  174.0|\n",
      "|    max|             34895|             23.6|               18.6|           1024.0|             586.6|    C|                 1386.0|\n",
      "+-------+------------------+-----------------+-------------------+-----------------+------------------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6. print the description of each columns.....\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- temperature: string (nullable = true)\n",
      " |-- var1: string (nullable = true)\n",
      " |-- pressure: string (nullable = true)\n",
      " |-- windspeed: string (nullable = true)\n",
      " |-- var2: string (nullable = true)\n",
      " |-- electricity_consumption: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7. print schema of the describe() function..\n",
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---------+---------+---------+\n",
      "|summary|temperature|     var1| pressure|windspeed|\n",
      "+-------+-----------+---------+---------+---------+\n",
      "|  count|  26,496.00|26,496.00|26,496.00|26,496.00|\n",
      "|   mean|       5.10|    -1.92|   986.45|    23.96|\n",
      "| stddev|       8.68|    10.42|    12.00|    48.28|\n",
      "|    min|     -17.10|   -32.90|   953.00|     1.08|\n",
      "|    max|      23.60|    18.60| 1,024.00|   586.60|\n",
      "+-------+-----------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8. now change the datatypes from string and format the decimals from the describe table......\n",
    "from pyspark.sql.functions import format_number\n",
    "result = df.describe()\n",
    "result.select(result['summary'],\n",
    "             format_number(result['temperature'].cast('float'),2).alias('temperature'),\n",
    "             format_number(result['var1'].cast('float'),2).alias('var1'),\n",
    "             format_number(result['pressure'].cast('float'),2).alias('pressure'),\n",
    "             format_number(result['windspeed'].cast('float'),2).alias('windspeed')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "| avg(temperature)|\n",
      "+-----------------+\n",
      "|5.098988526570052|\n",
      "+-----------------+\n",
      "\n",
      "+-------------------+\n",
      "|stddev(temperature)|\n",
      "+-------------------+\n",
      "|    8.6828603086732|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9. select the column 'temperature' and print the mean....and format the decimal points\n",
    "\n",
    "from pyspark.sql.functions import avg, stddev, format_number\n",
    "\n",
    "mean_temp = df.agg({'temperature':'mean'})\n",
    "std_temp = df.agg({'temperature':'std'})\n",
    "mean_temp.show()\n",
    "std_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|avg temperature|\n",
      "+---------------+\n",
      "|           5.10|\n",
      "+---------------+\n",
      "\n",
      "+---------------+\n",
      "|std temperature|\n",
      "+---------------+\n",
      "|           8.68|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10. change column name and values\n",
    "mean_temp = mean_temp.select(format_number(mean_temp['avg(temperature)'],2).alias(\"avg temperature\"))\n",
    "std_temp = std_temp.select(format_number(std_temp['stddev(temperature)'],2).alias(\"std temperature\"))\n",
    "mean_temp.show()\n",
    "std_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Ratio|\n",
      "+------+\n",
      "|-0.020|\n",
      "|-0.021|\n",
      "|-0.022|\n",
      "|-0.020|\n",
      "|-0.019|\n",
      "|-3.835|\n",
      "|-3.105|\n",
      "|-1.493|\n",
      "|-0.888|\n",
      "|-0.556|\n",
      "|-0.308|\n",
      "|-0.280|\n",
      "|-0.180|\n",
      "|-0.180|\n",
      "|-0.088|\n",
      "|-0.112|\n",
      "|-0.089|\n",
      "|-0.141|\n",
      "|-0.133|\n",
      "|-0.114|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#11. create a new dataframe with a column \"Ratio\": which is the ratio between temperature and windspeed.\n",
    "df2 = df.withColumn(\"Ratio\", df['temperature']/df['windspeed'])\n",
    "df2.select(format_number(df2['Ratio'],3).alias(\"Ratio\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 12, 16, 15, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12. what day had the highest temperature?\n",
    "df.orderBy(df['temperature'].desc()).head(2)[0][1] #1st row and 2nd item --> [0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|max windspeed|min windspeed|\n",
      "+-------------+-------------+\n",
      "|       586.60|         1.07|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#13. what is the maximum and minimum windspeed?\n",
    "from pyspark.sql.functions import max, min\n",
    "max_min = df.select(max('windspeed'), min('windspeed'))\n",
    "max_min = max_min.select(format_number(max_min['max(windspeed)'],2).alias('max windspeed'),\n",
    "                         format_number(max_min['min(windspeed)'],2).alias('min windspeed'))\n",
    "max_min.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. how many days was the temperature above 300?\n",
    "\n",
    "#Methods\n",
    "#Method 1. pythonic way \n",
    "df.filter(df['temperature'] > 20).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 2. sql syntax\n",
    "df.filter('temperature >20').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count(temperature)|\n",
      "+------------------+\n",
      "|               214|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method 3. 'count' as as function\n",
    "from pyspark.sql.functions import count\n",
    "result = df.filter(df['temperature'] > 20)\n",
    "result.select(count('temperature')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.745471014492756"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. what percentage was the pressure greater than 1000?\n",
    "result = df.filter(df['pressure'] > 1000).count()\n",
    "result1 = df.count()\n",
    "(result/result1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.745471014492756"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "(df.filter(df['pressure'] > 1000).count() / df.count()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|corr(temperature, pressure)|\n",
      "+---------------------------+\n",
      "|        -0.7239385216901104|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#15. what is the correlation between temperature and pressure?\n",
    "from pyspark.sql.functions import corr\n",
    "df.select(corr('temperature','pressure')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|year|max(temperature)|\n",
      "+----+----------------+\n",
      "|2015|            22.1|\n",
      "|2013|            22.1|\n",
      "|2014|            23.6|\n",
      "|2016|            23.6|\n",
      "|2017|            23.6|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#16. what is the max temperature per year?\n",
    "from pyspark.sql.functions import year\n",
    "new = df.withColumn(\"year\", year(df['datetime']))\n",
    "new = new.groupBy(\"year\").max()\n",
    "new.select(['year','max(temperature)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|month|avg(month)|\n",
      "+-----+----------+\n",
      "|   12|      12.0|\n",
      "|    1|       1.0|\n",
      "|    6|       6.0|\n",
      "|    3|       3.0|\n",
      "|    5|       5.0|\n",
      "|    9|       9.0|\n",
      "|    4|       4.0|\n",
      "|    8|       8.0|\n",
      "|    7|       7.0|\n",
      "|   10|      10.0|\n",
      "|   11|      11.0|\n",
      "|    2|       2.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#17. what is the average pressure for each month?\n",
    "from pyspark.sql.functions import month\n",
    "monthdf = df.withColumn('month', month(df['datetime']))\n",
    "new = monthdf.groupBy('month').avg()\n",
    "new = new.select(['month','avg(month)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
