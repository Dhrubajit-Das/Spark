{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('tree_models').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"D:\\\\Udemy course\\\\Spark\\\\MLLib\\\\College.csv\", inferSchema=True, header=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting up predictors into a vector....\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Apps',\n",
    " 'Accept',\n",
    " 'Enroll',\n",
    " 'Top10perc',\n",
    " 'Top25perc',\n",
    " 'F_Undergrad',\n",
    " 'P_Undergrad',\n",
    " 'Outstate',\n",
    " 'Room_Board',\n",
    " 'Books',\n",
    " 'Personal',\n",
    " 'PhD',\n",
    " 'Terminal',\n",
    " 'S_F_Ratio',\n",
    " 'perc_alumni',\n",
    " 'Expend',\n",
    " 'Grad_Rate'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transforming the data into vector....\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting the categorical target variable \"Private\" into numeric....\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='Private',outputCol='privateindex')\n",
    "new_df = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|privateindex|\n",
      "+--------------------+------------+\n",
      "|[1660.0,1232.0,72...|         0.0|\n",
      "|[2186.0,1924.0,51...|         0.0|\n",
      "|[1428.0,1097.0,33...|         0.0|\n",
      "|[417.0,349.0,137....|         0.0|\n",
      "|[193.0,146.0,55.0...|         0.0|\n",
      "|[587.0,479.0,158....|         0.0|\n",
      "|[353.0,340.0,103....|         0.0|\n",
      "|[1899.0,1720.0,48...|         0.0|\n",
      "|[1038.0,839.0,227...|         0.0|\n",
      "|[582.0,498.0,172....|         0.0|\n",
      "|[1732.0,1425.0,47...|         0.0|\n",
      "|[2652.0,1900.0,48...|         0.0|\n",
      "|[1179.0,780.0,290...|         0.0|\n",
      "|[1267.0,1080.0,38...|         0.0|\n",
      "|[494.0,313.0,157....|         0.0|\n",
      "|[1420.0,1093.0,22...|         0.0|\n",
      "|[4302.0,992.0,418...|         0.0|\n",
      "|[1216.0,908.0,423...|         0.0|\n",
      "|[1130.0,704.0,322...|         0.0|\n",
      "|[3540.0,2001.0,10...|         1.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final predictors and target variable....\n",
    "final_data = new_df.select(['features','privateindex'])\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split data\n",
    "train,test = final_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, RandomForestClassifier, GBTClassifier)\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(labelCol='privateindex', featuresCol='features')\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='privateindex',\n",
    "                                              predictionCol='prediction', metricName=\"f1\")    \n",
    "\n",
    "dtc_model = dTree.fit(train)\n",
    "dtc_pred = dtc_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 accuracy: 0.9086654520029194\n",
      "\n",
      "Confusion matrix....\n",
      "prediction    0.0  1.0\n",
      "privateindex          \n",
      "0.0           114    7\n",
      "1.0             9   47\n",
      "\n",
      "Classification report.....\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.94      0.93       121\n",
      "        1.0       0.87      0.84      0.85        56\n",
      "\n",
      "avg / total       0.91      0.91      0.91       177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(dtc))\n",
    "print(\"\")\n",
    "import pandas as pd\n",
    "predictions = dtc_pred.select('privateindex', 'prediction')\n",
    "pred = predictions.toPandas()\n",
    "print(\"Confusion matrix....\")\n",
    "print(pd.crosstab(pred['privateindex'],pred['prediction']))\n",
    "print(\"\")\n",
    "print(\"Classification report.....\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pred['privateindex'],pred['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree test accuracy: 0.9341794569067295\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluation_accu = BinaryClassificationEvaluator(labelCol='privateindex')\n",
    "print(\"DecisionTree test accuracy: {0}\".format(evaluation_accu.evaluate(dtc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  DecisionTree tuned model - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(labelCol='privateindex', featuresCol='features')\n",
    "pipeline = Pipeline(stages=[ dTree])\n",
    "\n",
    "# Search through decision tree's parameters for best model - 6 parameters to choose from......\n",
    "paramGrid = ParamGridBuilder().addGrid(dTree.maxDepth, [2,3,4,5,6,7]).addGrid(dTree.minInstancesPerNode,[1,2,3,4,5]).addGrid(dTree.minInfoGain,[0.0,0.1,0.2,0.3,0.4,0.5]).build()\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='privateindex',\n",
    "                                              predictionCol='prediction', metricName=\"f1\")    \n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_dtc_model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_432d93d0dc9faa25d9d8) of depth 3 with 15 nodes\n"
     ]
    }
   ],
   "source": [
    "tree_model = CV_dtc_model.bestModel.stages[-1]\n",
    "print(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 accuracy: 0.9041805171152231\n",
      "\n",
      "Confusion matrix....\n",
      "prediction    0.0  1.0\n",
      "privateindex          \n",
      "0.0           112    9\n",
      "1.0             8   48\n",
      "\n",
      "Classification report.....\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93       121\n",
      "        1.0       0.84      0.86      0.85        56\n",
      "\n",
      "avg / total       0.90      0.90      0.90       177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_tuned = CV_dtc_model.transform(test)\n",
    "print(evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(dtc_tuned))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix....\")\n",
    "import pandas as pd\n",
    "predictions = dtc_tuned.select('privateindex', 'prediction')\n",
    "pred = predictions.toPandas()\n",
    "print(pd.crosstab(pred['privateindex'],pred['prediction']))\n",
    "print(\"\")\n",
    "print(\"Classification report.....\")\n",
    "print(classification_report(pred['privateindex'],pred['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned DecisionTree test accuracy: 0.9637691853600945\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned DecisionTree test accuracy: {0}\".format(evaluation_accu.evaluate(dtc_tuned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(labelCol='privateindex', featuresCol='features')\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='privateindex',\n",
    "                                              predictionCol='prediction', metricName=\"f1\")    \n",
    "\n",
    "rfc_model = rfc.fit(train)\n",
    "rfc_pred = rfc_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 accuracy: 0.9311047381288879\n",
      "\n",
      "Confusion matrix....\n",
      "prediction    0.0  1.0\n",
      "privateindex          \n",
      "0.0           118    3\n",
      "1.0             9   47\n",
      "\n",
      "Classification report.....\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.98      0.95       121\n",
      "        1.0       0.94      0.84      0.89        56\n",
      "\n",
      "avg / total       0.93      0.93      0.93       177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(rfc_pred))\n",
    "print(\"\")\n",
    "import pandas as pd\n",
    "predictions = rfc_pred.select('privateindex', 'prediction')\n",
    "pred = predictions.toPandas()\n",
    "print(\"Confusion matrix....\")\n",
    "print(pd.crosstab(pred['privateindex'],pred['prediction']))\n",
    "print(\"\")\n",
    "print(\"Classification report.....\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pred['privateindex'],pred['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest test accuracy: 0.9818476977567887\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForest test accuracy: {0}\".format(evaluation_accu.evaluate(rfc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest tuned - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_tuned = RandomForestClassifier(labelCol='privateindex', featuresCol='features')\n",
    "pipeline = Pipeline(stages=[rfc_tuned])\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(rfc_tuned.numTrees, [30,60,90,120,150]).addGrid(rfc_tuned.maxDepth,[2,3,4,5,6,7,8,9]).build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='privateindex',\n",
    "                                              predictionCol='prediction', metricName=\"f1\")    \n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_rfc_model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RandomForest test accuracy: 0.9819952774498228\n",
      "f1 accuracy: 0.9141319467380143\n",
      "\n",
      "Confusion matrix....\n",
      "prediction    0.0  1.0\n",
      "privateindex          \n",
      "0.0           116    5\n",
      "1.0            10   46\n",
      "\n",
      "Classification report.....\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94       121\n",
      "        1.0       0.90      0.82      0.86        56\n",
      "\n",
      "avg / total       0.91      0.92      0.91       177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_test_tuned = CV_rfc_model.transform(test)\n",
    "print(\"Tuned RandomForest test accuracy: {0}\".format(evaluation_accu.evaluate(rfc_test_tuned)))\n",
    "print(evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(rfc_test_tuned))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix....\")\n",
    "import pandas as pd\n",
    "predictions = rfc_test_tuned.select('privateindex', 'prediction')\n",
    "pred = predictions.toPandas()\n",
    "print(pd.crosstab(pred['privateindex'],pred['prediction']))\n",
    "print(\"\")\n",
    "print(\"Classification report.....\")\n",
    "print(classification_report(pred['privateindex'],pred['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
